---
title: "Доказательство ЦПТ последовательной подменой слагаемых"
format:
  html:
    toc: true
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
bibliography: references.bib
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

::: {.hidden}
$$
 \newcommand\cN{{\mathcal{N}}}
 \newcommand\P{{\mathbb{P}}}
 \newcommand\E{{\mathbb{E}}}
 \DeclareMathOperator{\plim}{plim}
 \newcommand\Var{{\mathrm{Var}}}
 \newcommand\Cov{{\mathrm{Cov}}}
 \newcommand\Corr{{\mathrm{Corr}}}
$$
:::




:::{.callout-note}
## Лемма

Пусть $A$ — множество всех  (для каждой $f \in A$ найдётся константа $M$ такая, что $\abs{f'''(x)} < M$ при любом $x \in \mathbb{R}$).

Если для любой трижды дифференцируемой действительной функций с ограниченной третьей производной $h$ выполнено условие 
$$
\lim_{n\to\infty} \E(h(R_n)) = \E(h(R)),
$$
то последовательность случайных величин $(R_n)$ сходится к $R$ по распределению, то есть,
$$
\lim_{n\to\infty} \P(R_n \leq x) = \P(R\leq x),
$$
для любой точки $x$, в которой функция распределения $F$ величины $R$ непрерывна. 
:::



:::{.callout-caution collapse="true"}
## Доказательство леммы

Нам надо доказать, что при большом $n$ вероятность $\P(R_n\leq x)$ не может слишком сильно отличаться от вероятности $\P(R \leq x)$ ни в большую, ни в меньшую сторону. 

Докажем половину утверждения, вторая половина доказывается по аналогии. Основная идея доказательства такова: вероятность $\P(R_n \leq x)$ можно заменить на ожидание $\E(I(R_n \leq x))$, а «ступенчатый» индикатор $I$ можно сколь угодно точно приблизить гладкой много раз дифференцируемой функцией. 

Поехали. Выбираем произвольное $\varepsilon$. Наша цель — доказать, что начиная с некоторого $n$ вероятность $\P(R_n \leq x) > \P(R \leq x) - \varepsilon$. 

С помощью ожидания индикатора и функции распределения $F$ величины $R$ наша цель записывается так:
$$
\E(I(R_n \leq x)) > F(x) - \varepsilon.
$$

Отступим от точки $x$ чуть-чуть влево, в точку $x - \delta$. В силу непрерывности $F$ в точке $x$ размер оступа $\delta$ можно выбрать так, что $F(x-\delta) > F(x) - \varepsilon/2$. 

Теперь придумаем трижды дифференцируемую функцию $g$, которая чуть-чуть занижает индикатор $I(R_n \leq x)$. А именно, левее $x-\delta$ функция $g$ равна 1, правее $x$ функция $g$ равна нулю, а на отрезке $[x-\delta, x]$ функция $g$ плавно спускается от 1 к 0. По построению, 
$$
I(R_n \leq x - \delta) \leq g(R_n) \leq I(R_n \leq x).
$$
Делаем первый шаг по замене индикатора на не превосходящую его гладкую функцию $g$: 
$$
\P(R_n\leq x) = \E(I(R_n \leq x)) \geq \E(g(R_n)).
$$
Теперь выберем $n$ достаточно большим, так, чтобы 
$$
\E(g(R_n)) \geq \E(g(R)) - \varepsilon/2. 
$$
Теперь заменяем гладкую функцию $g$ на не превосходящий её индикатор,
$$
\E(g(R)) - \varepsilon/2 \geq \E(I(R \leq x-\delta)) - \varepsilon/2 = F(x-\delta) - \varepsilon/2.
$$
Вспоминаем, что точку $x-\delta$ мы выбрали недалеко от $x$ и получаем в итоге, что начиная с некоторого $n$
$$
\P(X_n \leq x) \geq F(x) - \varepsilon.
$$
Аналогично доказывается и вторая половина. На этот раз надо отступать от $x$ вправо в точку $x+\delta$, и заменять индикатор $I(R_n \leq x)$ мажорирующей его гладкой функцией $g$.  
:::



:::{.callout-caution collapse="true"}
## Упражнение к лемме

Докажите, что для любого $\varepsilon$ начиная  с некоторого $n$ выполнено неравенство 

$$
\P(X_n \leq x) \leq F(x) + \varepsilon.
$$

:::

:::{.callout-note}
## Центральная предельная теорема

Если величины $Q_1$, $Q_2$, \ldots, независимы и одинаково распределены с конечным ожиданием $\mu$ и дисперсией $\sigma^2$, то отмасштабированная сумма
$$
Z_n = \frac{\sum_{i=1}^n Q_i - \E(\sum_{i=1}^n Q_i)}{\sqrt{\Var(\sum_{i=1}^n Q_i)}}
$$
стремится по распределению к $\cN(0;1)$.
:::


Доказательство. 
Для начала представим $S_n$ в виде отмасштабированных слагаемых. 
$$
Z_n = \frac{Q_1 - \mu}{\sigma \sqrt n} + \ldots + \frac{Q_{n-1} - \mu}{\sigma \sqrt n} + \frac{Q_n - \mu}{\sigma \sqrt n} = X_1 + \ldots + X_{n-1} + X_n
$$
Замечаем, что $\E(X_i) = 0$, $\Var(X_i) = 1/n$.

Теперь по тихоньку начнем менять слагаемые в правом хвосте на независимые слагаемые $Y_i$ с таким же нулевым ожиданием, такой же дисперсией $1/n$, но нормально распределенные. 

Вторым индексом у $Z_{n,k}$ будем обозначать число оставшихся исходных слагаемых. 
Например,
$$
Z_n = Z_{n,n} = X_1 + \ldots + X_{n-2} +  X_{n-1} + X_n
$$
$$
Z_{n,n-1} = X_1 + \ldots + X_{n-2} +  X_{n-1} + Y_n
$$
$$
Z_{n,n-2} = X_1 + \ldots + X_{n-2} +  Y_{n-1} + Y_n
$$
И, наконец,
$$
Z_{n,0} = Y_1 + \ldots + Y_{n-2} +  Y_{n-1} + Y_n
$$








## Источники

В основном изложение следует статье [@Chin2022ASA]. Постарался сделать изложение более «мотивированным», чтобы перед шагами яснее была видна цель. Также излагаю один случай из повторяющихся. С одной стороны, это облегчает понимание, с другой стороны аналогичный случай можно решать в виде упражнения. 

