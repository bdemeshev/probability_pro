---
title: "Достаточная статистика"
format:
  html:
    toc: true
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
bibliography: references.bib
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

::: {.hidden}
$$
 \newcommand\cN{{\mathcal{N}}}
 \newcommand\P{{\mathbb{P}}}
 \newcommand\E{{\mathbb{E}}}
$$
:::

:::{.callout-tip}
## Неформальное определение

Функция $T=t(Y_1, Y_2, \ldots, Y_n)$ называется *достаточной статистикой* для параметра $a$, 
если для вычисления оценки максимального правдоподобия $\hat a$ *достаточно* знать только величину $T$.
:::

:::{.callout-note}
## Пример

Величины $Y_1$, $Y_2$, \ldots, $Y_n$ являются случайной выборкой из нормального распределения $\cN(\mu; 146)$.

Найдите достаточную статистику для параметра $\mu$.
:::

:::{.callout-caution collapse="true"}
## Решение

Например, достаточной статистикой будет $T=\sum Y_i$ или 
$T=2 \sum Y_i + 11$. 
Знания любой из этих величин достаточно, чтобы посчитать $\hat \mu$. Возможно много других вариантов достаточной статистики. 
:::


:::{.callout-note}
## Пример

Величины $Y_1$, $Y_2$, \ldots, $Y_n$ являются случайной выборкой из равномерного распределения $U[0; a]$.

Найдите достаточную статистику для параметра $a$.
:::

:::{.callout-caution collapse="true"}
## Решение

Например, достаточной статистикой будет $T=\max\{Y_1, \ldots, Y_n\}$ или 
$T= 11 + 2 / \max\{Y_1, \ldots, Y_n\}$. 
Знания любой из этих величин достаточно, чтобы посчитать $\hat a$. Возможно много других вариантов достаточной статистики. 
:::


Перед формальным определением посмотрим на мотивирующий пример. 

:::{.callout-note}
## Пример

Мы хотим оценить неизвестный параметр $a$.

Величины $Y_1$, $Y_2$, \ldots, $Y_n$ являются случайной выборкой из нормального распределения $\cN(5; a)$.

Величины $W_1$, $W_2$, \ldots, $W_n$ являются случайной выборкой из нормального распределения $\cN(5; 27)$.

Какая из двух выборок полезна для оценка параметра $a$?
:::

:::{.callout-caution collapse="true"}
## Предсказуемый ответ

Выборка $(Y_i)$ полезна, а выборка $(W_i)$ — бесполезна.
:::

И мы можем перейти к формальному определению. 

:::{.callout-tip}
## Формальное определение

Функция $T=t(Y_1, Y_2, \ldots, Y_n)$ называется *достаточной статистикой* для параметра $a$, если условный закон распределения

$$
(Y_1, Y_2, \ldots, Y_n \mid T)
$$
не зависит от параметра $a$. 
:::

Другими словами, знание $T$ делает выборку $Y_1$, $Y_2$, \ldots, $Y_n$ бесполезной для оценивания параметра $a$.

Формальное и неформальное определение связаны теоремой о факторизации. 

:::{.callout-tip}
## Теорема 

Функция $T=t(Y_1, Y_2, \ldots, Y_n)$ является достаточной статистикой для параметра $a$, 
если и только если совместная функция плотности наблюдений представима в виде произведения двух функций
$$
f(y_1, y_2, \ldots, y_n \mid a) = g(y_1, y_2, \ldots, y_n) \cdot h(a, t).
$$
:::
Функция $g$ не зависит от неизвестного параметра $a$, а функция 
$h$ зависит от наблюдений только «через» достаточную статистику $t$. 




:::{.callout-note}
## Пример

Величины $(Y_i)$ независимы и имеют распределение Бернулли с неизвестным параметром $p$. 

1. Найдите вероятность $\P(Y_1 = 1, Y_2 = 0, Y_3 = 1)$.

2. Найдите вероятность $\P(Y_1 = y_1, Y_2 = y_2, \ldots,  Y_n = y_n)$ в общем виде. 

3. Без вычислений, опираясь на интуицию, найдите достаточную статистику для параметра $p$. 

4. Найдите вероятность $\P(Y_1 = 1, Y_2 = 0, Y_3 = 1 \mid T = 1)$, где $T=\sum Y_i$.

5. Найдите вероятность $\P(Y_1 = 1, Y_2 = 0, Y_3 = 1 \mid T = 2)$, где $T=\sum Y_i$.

6. Найдите вероятность $\P(Y_1 = y_1, Y_2 = y_2, \ldots,  Y_n = y_n \mid T= t)$, где $T=\sum Y_i$, в общем виде. Убедитесь, что эта вероятность не зависит от $p$. 
:::


:::{.callout-caution collapse="true"}
## Ответ

$$
\P(Y_1 = y_1, Y_2 = y_2, \ldots,  Y_n = y_n \mid T= t) = 
\begin{cases}
1/C_n^t, \text{ если } \sum y_i = t \\
0, \text{ иначе}.
\end{cases}
$$
:::

Зачем ещё полезна достаточная статистика? С помощью достаточной статистики зачастую можно улучшить другую оценку!

:::{.callout-tip}
## Теорема Рао-Блэквелла-Колмогорова

Если $\hat a$ — произвольная оценка параметра $a$ (не обязательно максимального правдоподобия), а функция $T=t(Y_1, Y_2, \ldots, Y_n)$ является достаточной статистикой для параметра $a$, то
новая оценка $\hat a' = \E(\hat a \mid T)$ не хуже исходной оценки $\hat a$ по среднеквадратичной ошибке

$$
\E[(\hat a' - a)^2] \leq \E[(\hat a - a)^2].
$$
:::

Правда, два раза подряд улучшить оценку не получится. 
Если $\hat a' = \E(\hat a \mid T)$, то вторая попытка улучшения, $\E(\hat a' \mid T)$, совпадёт с $\hat a'$. 
Новая оценка $\hat a'$ будет несмещённой, если и только если исходная оценка $\hat a$ была несмещённой. 



